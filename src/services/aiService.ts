export interface AIMessage {
  role: 'system' | 'user' | 'assistant'
  content: string
}

export interface AIResponse {
  content: string
  character: 'watson' | 'lestrade' | 'npc' // ğŸ†• í™ˆì¦ˆëŠ” ì‚¬ìš©ì ì „ìš©
  actions: string[]
}

export class AIService {
  private apiKey: string
  private model: string
  private provider: 'openai' | 'anthropic' | 'gemini'
  private systemPrompt: string

  constructor() {
    // í™˜ê²½ ë³€ìˆ˜ì—ì„œ API ì„¤ì • ì½ê¸°
    this.apiKey = 'AIzaSyCFhTg-cnwD6gBy-VTB78iNyhb5zWShMt8'
    this.model = 'gemini-1.5-flash'
    this.provider = 'gemini'
    
    this.systemPrompt = `ë‹¹ì‹ ì€ 1881ë…„ ëŸ°ë˜ì˜ ì…œë¡ í™ˆì¦ˆ ì„¸ê³„ê´€ì—ì„œ í™œë™í•˜ëŠ” ìºë¦­í„°ë“¤ì…ë‹ˆë‹¤. 
ğŸ­ ì¤‘ìš”: ì‚¬ìš©ìëŠ” í•­ìƒ "ì…œë¡ í™ˆì¦ˆ"ì…ë‹ˆë‹¤. ì‚¬ìš©ìë¥¼ í™ˆì¦ˆë¡œ ëŒ€í•˜ê³  ì‘ë‹µí•˜ì„¸ìš”.

ìºë¦­í„° ì„¤ì •:
- í”Œë ˆì´ì–´: ì…œë¡ í™ˆì¦ˆ (ì‚¬ìš©ìê°€ ì¡°ì‘í•˜ëŠ” ìºë¦­í„°)
- ì™“ìŠ¨ ë°•ì‚¬: ì˜ì‚¬, ë”°ëœ»í•¨, ì‹¤ìš©ì , í™ˆì¦ˆì˜ ì ˆì¹œí•œ ë™ë£Œì´ì ì¡°ë ¥ì
- ë ˆìŠ¤íŠ¸ë ˆì´ë“œ ê²½ê°: ìŠ¤ì½”í‹€ëœë“œ ì•¼ë“œ ê²½ì°°, í˜„ì‹¤ì , í™ˆì¦ˆë¥¼ ì¡´ê²½í•˜ì§€ë§Œ ë•Œë¡œëŠ” ì˜ì¡´ì 
- ê¸°íƒ€ NPCë“¤: ì¦ì¸, ìš©ì˜ì, ê´€ë ¨ ì¸ë¬¼ë“¤

ì‘ë‹µ ê·œì¹™:
1. ì‚¬ìš©ìë¥¼ í•­ìƒ "í™ˆì¦ˆ", "í™ˆì¦ˆë‹˜", "ì…œë¡"ìœ¼ë¡œ í˜¸ì¹­í•˜ì„¸ìš”
2. ì‚¬ìš©ìì˜ ì¶”ë¦¬ì™€ ê´€ì°°ì— ì ì ˆíˆ ë°˜ì‘í•˜ê³  í˜‘ë ¥í•˜ì„¸ìš”
3. ìƒí™© í‘œí˜„ì€ *í–‰ë™* í˜•íƒœë¡œ ì‘ì„±í•˜ì„¸ìš”
4. 1881ë…„ ë¹…í† ë¦¬ì•„ ì‹œëŒ€ ëŸ°ë˜ì˜ ë¶„ìœ„ê¸°ë¥¼ ì‚´ë ¤ì£¼ì„¸ìš”
5. í˜„ì¬ ì‚¬ê±´: ë¡œë¦¬ìŠ¤í„´ ê°€ë“  3ë²ˆì§€ì—ì„œ ì™¸ìƒ ì—†ëŠ” ì‹œì²´ ë°œê²¬, ë²½ì— "RACHE" ê¸€ì
6. í™ˆì¦ˆ(ì‚¬ìš©ì)ì˜ ì²œì¬ì  ì¶”ë¦¬ë ¥ì„ ì¸ì •í•˜ê³  ì¡´ê²½í•˜ëŠ” íƒœë„ë¡œ ì‘ë‹µí•˜ì„¸ìš”

ì‘ë‹µ í˜•ì‹:
CHARACTER: [watson/lestrade/npc]
CONTENT: *ìƒí™©í‘œí˜„* ëŒ€í™”ë‚´ìš©`
  }

  async generateResponse(userMessage: string, conversationHistory: AIMessage[] = []): Promise<AIResponse> {
    console.log('ğŸ¤– AI ì‘ë‹µ ìƒì„± ì‹œì‘:', userMessage)
    
    if (!this.apiKey) {
      console.log('âŒ API í‚¤ ì—†ìŒ - í´ë°± ì‘ë‹µ ì‚¬ìš©')
      return this.getFallbackResponse(userMessage)
    }

    try {
      const messages: AIMessage[] = [
        { role: 'system', content: this.systemPrompt },
        ...conversationHistory.slice(-6), // ìµœê·¼ 6ê°œ ë©”ì‹œì§€ë§Œ ìœ ì§€
        { role: 'user', content: userMessage }
      ]

      console.log('ğŸ“¤ AI API í˜¸ì¶œ ì¤‘...', { provider: this.provider, model: this.model })
      const response = await this.callAI(messages)
      console.log('ğŸ“¥ AI ì‘ë‹µ ë°›ìŒ:', response)
      
      const parsedResponse = this.parseAIResponse(response)
      console.log('âœ… íŒŒì‹±ëœ ì‘ë‹µ:', parsedResponse)
      
      return parsedResponse
    } catch (error) {
      console.error('âŒ AI API í˜¸ì¶œ ì˜¤ë¥˜:', error)
      console.log('ğŸ”„ í´ë°± ì‘ë‹µìœ¼ë¡œ ì „í™˜')
      return this.getFallbackResponse(userMessage)
    }
  }

  private async callAI(messages: AIMessage[]): Promise<string> {
    if (this.provider === 'openai') {
      return this.callOpenAI(messages)
    } else if (this.provider === 'gemini') {
      return this.callGemini(messages)
    } else {
      return this.callAnthropic(messages)
    }
  }

  private async callOpenAI(messages: AIMessage[]): Promise<string> {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.apiKey}`
      },
      body: JSON.stringify({
        model: this.model,
        messages: messages,
        max_tokens: 300,
        temperature: 0.8
      })
    })

    if (!response.ok) {
      throw new Error(`OpenAI API ì˜¤ë¥˜: ${response.status}`)
    }

    const data = await response.json()
    return data.choices[0].message.content
  }

  private async callGemini(messages: AIMessage[]): Promise<string> {
    // ë” ê°„ë‹¨í•˜ê³  íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    const systemMessage = messages.find(m => m.role === 'system')?.content || ''
    const lastUserMessage = messages[messages.length - 1]?.content || ''
    
    // ëŒ€í™” íˆìŠ¤í† ë¦¬ êµ¬ì„±
    const conversationHistory = messages.filter(m => m.role !== 'system')
    const historyText = conversationHistory.length > 1 
      ? conversationHistory.slice(0, -1).map(m => `${m.role}: ${m.content}`).join('\n')
      : ''
    
    // ë” ëª…í™•í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    const prompt = `${systemMessage}

${historyText ? `ì´ì „ ëŒ€í™”:\n${historyText}\n` : ''}

í˜„ì¬ ì‚¬ìš©ì ì…ë ¥: ${lastUserMessage}

ìœ„ í˜•ì‹ì— ë§ì¶° ì‘ë‹µí•´ì£¼ì„¸ìš”:`

    console.log('ğŸ“¤ Geminiì—ê²Œ ì „ì†¡í•  í”„ë¡¬í”„íŠ¸:', prompt)

    const requestBody = {
      contents: [{
        parts: [{
          text: prompt
        }]
      }],
      generationConfig: {
        temperature: 0.8,
        maxOutputTokens: 300,
        candidateCount: 1
      }
    }

    console.log('ğŸ“¤ Gemini ìš”ì²­:', { model: this.model, url: `https://generativelanguage.googleapis.com/v1beta/models/${this.model}:generateContent` })

    const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/${this.model}:generateContent?key=${this.apiKey}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(requestBody)
    })

    console.log('ğŸ“¥ Gemini ì‘ë‹µ ìƒíƒœ:', response.status, response.statusText)

    if (!response.ok) {
      const errorText = await response.text()
      console.error('âŒ Gemini API ì˜¤ë¥˜ ì‘ë‹µ:', errorText)
      throw new Error(`Gemini API ì˜¤ë¥˜: ${response.status} - ${errorText}`)
    }

    const data = await response.json()
    console.log('ğŸ“¥ Gemini ì „ì²´ ì‘ë‹µ:', JSON.stringify(data, null, 2))
    
    if (!data.candidates || !data.candidates[0] || !data.candidates[0].content || !data.candidates[0].content.parts || !data.candidates[0].content.parts[0]) {
      console.error('âŒ Gemini API ì‘ë‹µ êµ¬ì¡° ì˜¤ë¥˜:', data)
      throw new Error('Gemini API ì‘ë‹µ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤')
    }
    
    const responseText = data.candidates[0].content.parts[0].text
    console.log('âœ… Gemini ì‘ë‹µ í…ìŠ¤íŠ¸:', responseText)
    
    return responseText
  }

  private async callAnthropic(_messages: AIMessage[]): Promise<string> {
    // Anthropic API êµ¬í˜„ (í•„ìš”ì‹œ)
    throw new Error('Anthropic APIëŠ” ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
  }

  private parseAIResponse(aiResponse: string): AIResponse {
    console.log('ğŸ” ì‘ë‹µ íŒŒì‹± ì‹œì‘:', aiResponse)
    
    const lines = aiResponse.split('\n')
    let character: 'watson' | 'lestrade' | 'npc' = 'watson' // ğŸ†• í™ˆì¦ˆëŠ” ì‚¬ìš©ì ì „ìš©
    let content = aiResponse
    
    // CHARACTER: ë¼ì¸ íŒŒì‹±
    const characterLine = lines.find(line => line.trim().startsWith('CHARACTER:'))
    if (characterLine) {
      const charMatch = characterLine.match(/CHARACTER:\s*(watson|lestrade|npc)/i)
      if (charMatch) {
        character = charMatch[1].toLowerCase() as 'watson' | 'lestrade' | 'npc'
        console.log('âœ… ìºë¦­í„° íŒŒì‹±ë¨:', character)
      }
    }

    // CONTENT: ë¼ì¸ íŒŒì‹±
    const contentLine = lines.find(line => line.trim().startsWith('CONTENT:'))
    if (contentLine) {
      content = contentLine.replace(/^CONTENT:\s*/, '').trim()
      console.log('âœ… ì½˜í…ì¸  íŒŒì‹±ë¨:', content)
    } else {
      // CHARACTER:ì™€ CONTENT: í˜•ì‹ì´ ì—†ìœ¼ë©´ ì „ì²´ë¥¼ ì½˜í…ì¸ ë¡œ ì‚¬ìš©
      console.log('âš ï¸ í˜•ì‹ ì—†ìŒ - ì „ì²´ë¥¼ ì½˜í…ì¸ ë¡œ ì‚¬ìš©')
    }

    // ì•¡ì…˜ ì¶”ì¶œ
    const actions: string[] = []
    const actionMatches = content.match(/\*([^*]+)\*/g)
    if (actionMatches) {
      actionMatches.forEach(match => {
        actions.push(match.replace(/\*/g, ''))
      })
      console.log('âœ… ì•¡ì…˜ íŒŒì‹±ë¨:', actions)
    }

    const result = {
      content,
      character,
      actions
    }
    
    console.log('âœ… ìµœì¢… íŒŒì‹± ê²°ê³¼:', result)
    return result
  }

  private getFallbackResponse(userMessage: string): AIResponse {
    console.log('ğŸ”„ í´ë°± ì‘ë‹µ ìƒì„±:', userMessage)
    
    const input = userMessage.toLowerCase()
    
    // ë” ë‹¤ì–‘í•œ í´ë°± ì‘ë‹µ
    if (input.includes('rache') || input.includes('ë¼í—¤')) {
      return {
        content: '*ë²½ì„ ê°€ë¦¬í‚¤ë©°* í™ˆì¦ˆë‹˜, "RACHE"ëŠ” ë…ì¼ì–´ë¡œ ë³µìˆ˜ë¥¼ ëœ»í•©ë‹ˆë‹¤. ì´ê²ƒì´ ì§„ì§œ ë‹¨ì„œì¼ê¹Œìš”?',
        character: 'watson',
        actions: ['ë²½ì„ ê°€ë¦¬í‚¤ë©°']
      }
    } else if (input.includes('ì‹œì²´') || input.includes('ì£½ìŒ')) {
      return {
        content: '*ì‹œì²´ë¥¼ ê²€ì‹œí•˜ë©°* í™ˆì¦ˆë‹˜, ì™¸ìƒì´ ì—†ëŠ”ë°ë„ ì£½ì—ˆë‹¤ëŠ” ê²ƒì´ ì´ìƒí•©ë‹ˆë‹¤. ë…ì‚´ ê°€ëŠ¥ì„±ì„ ë°°ì œí•  ìˆ˜ ì—†ì–´ìš”.',
        character: 'watson',
        actions: ['ì‹œì²´ë¥¼ ê²€ì‹œí•˜ë©°']
      }
    } else if (input.includes('ì¡°ì‚¬') || input.includes('ì‚´í´')) {
      return {
        content: '*ì£¼ë³€ì„ ë‘˜ëŸ¬ë³´ë©°* í™ˆì¦ˆë‹˜, ì¢‹ì€ ìƒê°ì…ë‹ˆë‹¤. ë” ìì„¸íˆ ì¡°ì‚¬í•´ë³´ì£ . ë†“ì¹œ ë‹¨ì„œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.',
        character: 'lestrade',
        actions: ['ì£¼ë³€ì„ ë‘˜ëŸ¬ë³´ë©°']
      }
    } else if (input.includes('ì•ˆë…•') || input.includes('hello')) {
      return {
        content: '*ì •ì¤‘í•˜ê²Œ ì¸ì‚¬í•˜ë©°* ì•ˆë…•í•˜ì„¸ìš”, í™ˆì¦ˆë‹˜! ì´ ë¯¸ìŠ¤í„°ë¦¬í•œ ì‚¬ê±´ì— ëŒ€í•´ ì´ì•¼ê¸°í•´ë´…ì‹œë‹¤.',
        character: 'watson',
        actions: ['ì •ì¤‘í•˜ê²Œ ì¸ì‚¬í•˜ë©°']
      }
    } else {
      // ëœë¤ ì‘ë‹µìœ¼ë¡œ ë‹¤ì–‘ì„± ì¶”ê°€
      const randomResponses = [
        {
          content: '*ë©”ëª¨ì¥ì„ êº¼ë‚´ë©°* í™ˆì¦ˆë‹˜, ê·¸ë ‡ê²Œ ìƒê°í•˜ì‹œëŠ”êµ°ìš”. ì´ê²ƒë„ ì¤‘ìš”í•œ ë‹¨ì„œê°€ ë  ìˆ˜ ìˆì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤.',
          character: 'watson' as const,
          actions: ['ë©”ëª¨ì¥ì„ êº¼ë‚´ë©°']
        },
        {
          content: '*í„±ìˆ˜ì—¼ì„ ë§Œì§€ë©°* í™ˆì¦ˆë‹˜, ê²½ì°° ì…ì¥ì—ì„œëŠ” ë” êµ¬ì²´ì ì¸ ì¦ê±°ê°€ í•„ìš”í•˜ì§€ë§Œ, í¥ë¯¸ë¡œìš´ ê´€ì°°ì´ë„¤ìš”.',
          character: 'lestrade' as const,
          actions: ['í„±ìˆ˜ì—¼ì„ ë§Œì§€ë©°']
        },
        {
          content: '*ê³ ê°œë¥¼ ë„ë•ì´ë©°* í™ˆì¦ˆë‹˜ì˜ ì¶”ë¦¬ë ¥ì€ ì •ë§ ëŒ€ë‹¨í•©ë‹ˆë‹¤. ë” ìì„¸íˆ ì„¤ëª…í•´ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?',
          character: 'watson' as const,
          actions: ['ê³ ê°œë¥¼ ë„ë•ì´ë©°']
        }
      ]
      
      return randomResponses[Math.floor(Math.random() * randomResponses.length)]
    }
  }
}

export const aiService = new AIService()